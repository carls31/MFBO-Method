{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "117d3726",
   "metadata": {},
   "source": [
    "# Gaussian process regression - hands on implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a6f995",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb462c6",
   "metadata": {},
   "source": [
    "This notebook contains a complete implementation of a Gaussian Process Regressor (GPR) with a squared exponential kernel using Numpy for matrix operations and Plotly for visualisation. \n",
    "\n",
    "The purpose of this notebook is to understand the main components of a GPR and to visualise the effects of certain parameters on the output. \n",
    "It is _not_ intended as a theoretical introduction to GPRs.\n",
    "A good introduction can be found [here](http://www.gaussianprocess.org/gpml/chapters/RW.pdf). \n",
    "\n",
    "Stable and effective implementations of GPR's are available, for example, in the [gpytorch](https://gpytorch.ai) package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc98796",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ebe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import interact, widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575ccbd",
   "metadata": {},
   "source": [
    "## Plotting helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa8c0bf",
   "metadata": {},
   "source": [
    "To have nice visualizations of the later GPR, we use Plotly and to have structured and lean code, we define a few commonly used 'helpers' here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8a0219",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def update_layout_of_graph(fig: go.Figure,title: str = 'Plot')->go.Figure:\n",
    "    fig.update_layout(\n",
    "        width=800,\n",
    "        height=600,\n",
    "        autosize=False,\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        title=title,\n",
    "        \n",
    "    )\n",
    "    fig.update_layout(plot_bgcolor='rgba(0,0,0,0)',\n",
    "                      xaxis_title = 'input values',\n",
    "                      yaxis_title = 'output values',\n",
    "                      legend=dict(yanchor=\"top\",\n",
    "                                  y=0.9,\n",
    "                                  xanchor=\"right\",\n",
    "                                  x=0.95),\n",
    "                      title={\n",
    "                          'x': 0.5,\n",
    "                          'xanchor': 'center'\n",
    "                      })\n",
    "    fig.update_xaxes(showline=True, linewidth=1, linecolor='black')\n",
    "    fig.update_yaxes(showline=True, linewidth=1, linecolor='black')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5a661",
   "metadata": {
    "code_folding": [
     0,
     6
    ]
   },
   "outputs": [],
   "source": [
    "def line_scatter(\n",
    "    visible: bool = True,\n",
    "    x_lines: np.array = np.array([]),\n",
    "    y_lines: np.array = np.array([]),\n",
    "    name_line: str = 'Predicted function',\n",
    "    showlegend: bool = True,\n",
    ") -> go.Scatter:\n",
    "    # Adding the lines\n",
    "    return go.Scatter(\n",
    "        visible=visible,\n",
    "        line=dict(color=\"blue\", width=2),\n",
    "        x=x_lines,\n",
    "        y=y_lines,\n",
    "        name=name_line,\n",
    "        showlegend= showlegend\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b4e5ac",
   "metadata": {
    "code_folding": [
     0,
     6
    ]
   },
   "outputs": [],
   "source": [
    "def dot_scatter(\n",
    "    visible: bool = True,\n",
    "    x_dots: np.array = np.array([]),\n",
    "    y_dots: np.array = np.array([]),\n",
    "    name_dots: str = 'Observed points',\n",
    "    showlegend: bool = True\n",
    ") -> go.Scatter:\n",
    "    # Adding the dots\n",
    "    return go.Scatter(\n",
    "        x=x_dots,\n",
    "        visible=visible,\n",
    "        y=y_dots,\n",
    "        mode=\"markers\",\n",
    "        name=name_dots,\n",
    "        marker=dict(color='red', size=8),\n",
    "        showlegend=showlegend\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda25c4",
   "metadata": {
    "code_folding": [
     0,
     6
    ]
   },
   "outputs": [],
   "source": [
    "def uncertainty_area_scatter(\n",
    "        visible: bool = True,\n",
    "        x_lines: np.array = np.array([]),\n",
    "        y_upper: np.array = np.array([]),\n",
    "        y_lower: np.array = np.array([]),\n",
    "        name: str = \"mean plus/minus standard deviation\",\n",
    ") -> go.Scatter:\n",
    "\n",
    "    return go.Scatter(\n",
    "        visible=visible,\n",
    "        x=np.concatenate((x_lines, x_lines[::-1])),  # x, then x reversed\n",
    "        # upper, then lower reversed\n",
    "        y=np.concatenate((y_upper, y_lower[::-1])),\n",
    "        fill='toself',\n",
    "        fillcolor='rgba(189,195,199,0.5)',\n",
    "        line=dict(color='rgba(200,200,200,0)'),\n",
    "        hoverinfo=\"skip\",\n",
    "        showlegend=True,\n",
    "        name= name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0be169",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def add_slider_GPR(figure: go.Figure, parameters):\n",
    "    figure.data[0].visible = True\n",
    "    figure.data[1].visible = True\n",
    "\n",
    "    # Create and add slider\n",
    "    steps = []\n",
    "    for i in range(int((len(figure.data) - 1) / 2)):\n",
    "        step = dict(\n",
    "            method=\"update\",\n",
    "            label=f'{parameters[i]: .2f}',\n",
    "            args=[{\n",
    "                \"visible\": [False] * (len(figure.data) - 1) + [True]\n",
    "            }],\n",
    "        )\n",
    "        step[\"args\"][0][\"visible\"][2 *\n",
    "                                   i] = True  # Toggle i'th trace to \"visible\"\n",
    "        step[\"args\"][0][\"visible\"][2 * i + 1] = True\n",
    "        steps.append(step)\n",
    "\n",
    "    sliders = [dict(\n",
    "        active=0,\n",
    "        pad={\"t\": 50},\n",
    "        steps=steps,\n",
    "    )]\n",
    "    figure.update_layout(sliders=sliders, )\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44e383",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def add_slider_to_function(figure:go.Figure, parameters):\n",
    "    figure.data[0].visible = True\n",
    "\n",
    "    # Create and add slider\n",
    "    steps = []\n",
    "    for i in range(len(figure.data)):\n",
    "        step = dict(\n",
    "            method=\"update\",\n",
    "            label=f'{parameters[i]: .2f}',\n",
    "            args=[{\n",
    "                \"visible\": [False] *len(figure.data) \n",
    "            }],\n",
    "        )\n",
    "        step[\"args\"][0][\"visible\"][i] = True  # Toggle i'th trace to \"visible\"\n",
    "        steps.append(step)\n",
    "\n",
    "    sliders = [dict(\n",
    "        active=0,\n",
    "        pad={\"t\": 50},\n",
    "        steps=steps,\n",
    "    )]\n",
    "    figure.update_layout(sliders=sliders, )\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058664e",
   "metadata": {},
   "source": [
    "## Implementation of GPR with squared exponential kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa792ab3",
   "metadata": {},
   "source": [
    "In order to define a gaussian process regressor (GPR) we need a covariance function (also called kernel). The choice of this function will determine the 'shape' of the later GPR. \n",
    "\n",
    "In this notebook we choose the popular _squared exponential_ kernel:\n",
    "$$ k(x_1,x_2):= \\sigma^2*\\exp(-\\|x_1-x_2\\|^2_2)/(2*l^2))$$\n",
    "with $$l>0$$ the lengthscale and $$\\sigma^2>0$$ the signal variance. \n",
    "You are encouraged to implement a different kernel and see the difference in the resulting GPR!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc55090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquaredExponentialKernel:\n",
    "    def __init__(self, sigma_f: float = 1, length: float = 1):\n",
    "        self.sigma_f = sigma_f\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, argument_1: np.array, argument_2: np.array) -> float:\n",
    "        return float(self.sigma_f *\n",
    "                     np.exp(-(np.linalg.norm(argument_1 - argument_2)**2) /\n",
    "                            (2 * self.length**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23258da",
   "metadata": {},
   "source": [
    "Let us visualize this kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lines = np.arange(-10, 10, 0.1)\n",
    "kernel = SquaredExponentialKernel(length=1)\n",
    "\n",
    "fig0 = go.FigureWidget(data=[\n",
    "    line_scatter(\n",
    "        x_lines=x_lines,\n",
    "        y_lines=np.array([kernel(x, 0) for x in x_lines]),\n",
    "    )\n",
    "])\n",
    "\n",
    "fig0 = update_layout_of_graph(fig0, title='Squared exponential kernel')\n",
    "\n",
    "\n",
    "@interact(length=(0.1, 3, 0.1), argument_2=(-10, 10, 0.1))\n",
    "def update(length=1, argument_2=0):\n",
    "    with fig0.batch_update():\n",
    "        kernel = SquaredExponentialKernel(length=length)\n",
    "        fig0.data[0].y = np.array([kernel(x, argument_2) for x in x_lines])\n",
    "\n",
    "\n",
    "fig0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a3946",
   "metadata": {},
   "source": [
    "In the practical implementation of the GPR you will face a couple of stability problems. Among others, numeric approximations in dealing with matrix (operations) may lead to non-invertible/non-positive-semi-definite covariance matrices which result in errors when calculating the GPR. \n",
    "\n",
    "In order to prevent this error we add the _machine epsilon_ to the diagonal of the later covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.finfo(float).eps)\n",
    "# 2.22044604925e-16\n",
    "\n",
    "print(np.finfo(np.float32).eps)\n",
    "# 1.19209e-07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f81bfc",
   "metadata": {},
   "source": [
    "Let us shortly recall the formula:\n",
    "Given training points $x_1,...,x_n\\in \\mathbb{R}^m$ with values $y_1,...,y_n\\in \\mathbb{R}$, $y = (y_i)\\in \\mathbb{R}^n$ with noise in each point $\\mathcal{N}_{0,\\sigma}$  and points $x_{n+1},...,x_k\\in \\mathbb{R}^m$ for which we want to predict the output, adapting our probability distribution leads to:\n",
    "\n",
    "$$\\mathcal{N}(K_*K^{-1}y,K_{**}-K_*K^{-1}K_*^T)$$\n",
    "with \n",
    "$$K= (k(x_i,x_j))_{i,j\\leq n}+\\sigma^2*\\mathbb{1}_n$$\n",
    "$$K_*= (k(x_i,x_j))_{n+1\\leq i, j\\leq n}$$\n",
    "$$K_{**}= (k(x_i,x_j))_{n+1\\leq i,j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c65a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to calculate the respective covariance matrices\n",
    "def cov_matrix(x1, x2, cov_function) -> np.array:\n",
    "    return np.array([[cov_function(a, b) for a in x1] for b in x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bdfc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPR:\n",
    "    def __init__(self,\n",
    "                 data_x: np.array,\n",
    "                 data_y: np.array,\n",
    "                 covariance_function=SquaredExponentialKernel(),\n",
    "                 white_noise_sigma: float = 0.01):\n",
    "        self.noise = white_noise_sigma\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.covariance_function = covariance_function\n",
    "\n",
    "        # Store the inverse of covariance matrix of input (+ machine epsilon on diagonal) since it is needed for every prediction\n",
    "        self._inverse_of_covariance_matrix_of_input = np.linalg.inv(\n",
    "            cov_matrix(data_x, data_x, covariance_function) +\n",
    "            (3e-7 + self.noise) * np.identity(len(self.data_x)))\n",
    "\n",
    "        self._memory = None\n",
    "\n",
    "    # function to predict output at new input values. Store the mean and covariance matrix in memory.\n",
    "\n",
    "    def predict(self, at_values: np.array) -> np.array:\n",
    "        k_lower_left = cov_matrix(self.data_x, at_values,\n",
    "                                  self.covariance_function)\n",
    "        k_lower_right = cov_matrix(at_values, at_values,\n",
    "                                   self.covariance_function)\n",
    "\n",
    "        # Mean.\n",
    "        mean_at_values = np.dot(\n",
    "            k_lower_left,\n",
    "            np.dot(self.data_y,\n",
    "                   self._inverse_of_covariance_matrix_of_input.T).T).flatten()\n",
    "\n",
    "        # Covariance.\n",
    "        cov_at_values = k_lower_right - \\\n",
    "            np.dot(k_lower_left, np.dot(\n",
    "                self._inverse_of_covariance_matrix_of_input, k_lower_left.T))\n",
    "\n",
    "        # Adding value larger than machine epsilon to ensure positive semi definite\n",
    "        cov_at_values = cov_at_values + 3e-7 * np.ones(\n",
    "            np.shape(cov_at_values)[0])\n",
    "\n",
    "        var_at_values = np.diag(cov_at_values)\n",
    "\n",
    "        self._memory = {\n",
    "            'mean': mean_at_values,\n",
    "            'covariance_matrix': cov_at_values,\n",
    "            'variance': var_at_values\n",
    "        }\n",
    "        return mean_at_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b586e",
   "metadata": {},
   "source": [
    "That's it. The GPR is ready to be used! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2f744",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decbe1a4",
   "metadata": {},
   "source": [
    "Let us initialize our GPR on a random training set and visualize the GPR. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9aa377",
   "metadata": {},
   "source": [
    "### Initializing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f62ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#df = pd.read_excel('Case5_1st_launch_WingsConvCoeffs_Info.xlsx')\n",
    "#df = pd.read_excel('2D_Flap0_to_30_WingsConvCoeffs.xlsm')\n",
    "df = pd.read_csv('Case3_2nd_launch_WingsConvCoeffs_Info.csv', sep=\";\")\n",
    "df = df[df['Unnamed: 47'] == 'CONVERGED']\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42 )\n",
    "\n",
    "#train_x = train.awa.to_numpy()\n",
    "#test_x  = test.awa.to_numpy()\n",
    "train_x = train.alpha0.to_numpy()\n",
    "test_x  = test.alpha0.to_numpy()\n",
    "train_y = train.Cy0Mean.to_numpy()\n",
    "test_y  = test.Cy0Mean.to_numpy()\n",
    "\n",
    "# normalize features\n",
    "mean = train_x.mean( )\n",
    "std = train_x.std( ) + 1e-6 # prevent dividing by 0\n",
    "train_x = (train_x - mean) / std\n",
    "test_x = (test_x - mean) / std\n",
    "\n",
    "# normalize labels\n",
    "mean, std = train_y.mean(),train_y.std()\n",
    "train_y = (train_y - mean) / std\n",
    "test_y = (test_y - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f59452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY GP MODEL \n",
    "# ADAPT THE CODE IN A ALL-IN-ONE FUNCTION \n",
    "x_values = np.array(train_x)\n",
    "y_values = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf9cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(x_values.min(),x_values.max(),0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8410f233",
   "metadata": {},
   "source": [
    "### Plot the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe426230",
   "metadata": {},
   "source": [
    "Let us define a helper function which returns a list of all plots of data points, mean, etc. needed to plot a GPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b06c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_GPR(data_x, data_y, model, x, visible=True) -> list:\n",
    "    mean = model.predict(x)\n",
    "\n",
    "    std = np.sqrt(model._memory['variance'])\n",
    "    data = []\n",
    "\n",
    "    for i in range(1, 4):\n",
    "        data.append(\n",
    "            uncertainty_area_scatter(\n",
    "                x_lines=x,\n",
    "                y_lower=mean - i * std,\n",
    "                y_upper=mean + i * std,\n",
    "                name=f\"mean plus/minus {i}*standard deviation\",\n",
    "                visible=visible))\n",
    "\n",
    "    data.append(line_scatter(x_lines=x, y_lines=mean, visible=visible))\n",
    "    data.append(dot_scatter(x_dots=data_x, y_dots=data_y, visible=visible))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cd9df1",
   "metadata": {},
   "source": [
    "Now, we can visualize our first GPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPR(x_values, y_values)\n",
    "data = plot_GPR(data_x=x_values, data_y=y_values, x=x, model=model)\n",
    "fig4 = go.Figure(data=data)\n",
    "fig4 = update_layout_of_graph(fig=fig4,\n",
    "                              title='GPR with length 1, sigma 0 and noise 0')\n",
    "\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409d823",
   "metadata": {},
   "source": [
    "A cool feature of the GPR is that it is sort of a probability distribution over function - so we can literally 'draw' random functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPR(x_values, y_values, white_noise_sigma = 0.75)\n",
    "\n",
    "mean = model.predict(x)\n",
    "covariance_matrix = model._memory['covariance_matrix']\n",
    "\n",
    "fig1 = go.FigureWidget(data=[dot_scatter(x_dots=x_values, y_dots=y_values)])\n",
    "fig1 = update_layout_of_graph(\n",
    "    fig1,\n",
    "    title='Random drawings (i.e. random functions) of the Gaussian process')\n",
    "\n",
    "button = widgets.Button(description='Add random drawing')\n",
    "\n",
    "\n",
    "def update(_):\n",
    "    with fig1.batch_update():\n",
    "        fig1.add_trace(\n",
    "            line_scatter(x_lines=x,\n",
    "                         y_lines=np.random.multivariate_normal(\n",
    "                             mean, covariance_matrix),\n",
    "                         name_line='random function',\n",
    "                         showlegend=False))\n",
    "        fig1.add_trace(\n",
    "            dot_scatter(x_dots=x_values, y_dots=y_values, showlegend=False))\n",
    "\n",
    "\n",
    "button.on_click(update)\n",
    "widgets.VBox([fig1, button])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ee73f",
   "metadata": {},
   "source": [
    "Doing predictions with a GPR is usually done by taking the mean function as our best guess. Since GPR's are a probabilistic model, we get in addition some sort of certainty of our prediction. (But be careful how to interpret this uncertainty area! Believing that every 'new' point must be in the uncertainty area is simply wrong!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36354bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPR(x_values[:1], y_values[:1])\n",
    "\n",
    "data = plot_GPR(data_x=x_values[:1], data_y=y_values[:1], x=x, model=model)\n",
    "\n",
    "fig2 = go.FigureWidget(data=data)\n",
    "fig2 = update_layout_of_graph(fig2, title='Prediction (i.e. mean) of GPR')\n",
    "\n",
    "button = widgets.Button(description='Add data point')\n",
    "\n",
    "number_of_points = 1\n",
    "\n",
    "# we update the y values of our 4 scatter plots \n",
    "def update(_):\n",
    "    with fig2.batch_update():\n",
    "        global number_of_points\n",
    "        if number_of_points < len(x_values):\n",
    "            number_of_points += 1\n",
    "            model = GPR(x_values[:number_of_points],\n",
    "                        y_values[:number_of_points])\n",
    "            mean = model.predict(x)\n",
    "            fig2.data[3].y = mean\n",
    "            for i in range(1, 4):\n",
    "                y_upper = mean + i * np.sqrt(model._memory['variance'])\n",
    "                y_lower = mean - i * np.sqrt(model._memory['variance'])\n",
    "                fig2.data[i - 1].y = np.concatenate((y_upper, y_lower[::-1]))\n",
    "\n",
    "            fig2.data[4].x = x_values[:number_of_points]\n",
    "            fig2.data[4].y = y_values[:number_of_points]\n",
    "\n",
    "\n",
    "button.on_click(update)\n",
    "widgets.VBox([fig2, button])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce23fd04",
   "metadata": {},
   "source": [
    "You can test the GPR with different data. Try using multi-dimensional input!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d17146a",
   "metadata": {},
   "source": [
    "### Visualization of effect of free parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e03650",
   "metadata": {},
   "source": [
    "Awesome! Now that we can make predictions with our GPR, lets visualize how the GPR changes if we change the free parameters, i.e. length-scale, variance and white noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPR(x_values,\n",
    "            y_values,\n",
    "            covariance_function=SquaredExponentialKernel(length=0.5),\n",
    "            white_noise_sigma=0.1)\n",
    "\n",
    "data = plot_GPR(x_values, y_values, model=model, x=x)\n",
    "\n",
    "fig3 = go.FigureWidget(data=data)\n",
    "\n",
    "\n",
    "# we update the y values of our 4 scatter plots \n",
    "@interact(sigma=(0.01, 3, 0.01), length=(0.01, 3, 0.01), noise=(0, 3, 0.1))\n",
    "def update(sigma=1, length=0.5, noise=0.1):\n",
    "    with fig3.batch_update():\n",
    "        model = GPR(x_values,\n",
    "                    y_values,\n",
    "                    covariance_function=SquaredExponentialKernel(\n",
    "                        sigma_f=sigma, length=length),\n",
    "                    white_noise_sigma=noise)\n",
    "\n",
    "        mean = model.predict(x)\n",
    "        y_upper = mean + np.sqrt(model._memory['variance'])\n",
    "        y_lower = mean - np.sqrt(model._memory['variance'])\n",
    "\n",
    "        \n",
    "        for i in range(1, 4):\n",
    "            y_upper = mean + i * np.sqrt(model._memory['variance'])\n",
    "            y_lower = mean - i * np.sqrt(model._memory['variance'])\n",
    "            fig3.data[i-1].y = np.concatenate((y_upper, y_lower[::-1]))\n",
    "        \n",
    "        fig3.data[3].y = mean\n",
    "\n",
    "\n",
    "fig3 = update_layout_of_graph(\n",
    "    fig3, title=\"GPR with varying length, sigma and white noise\")\n",
    "fig3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188b1f24",
   "metadata": {},
   "source": [
    "Pretty impressive how many function 'shapes' we can generate with a GPR!\n",
    "\n",
    "But now we naturally raise the question:\n",
    "\n",
    "_What are the best parameters for our GPR and problem?_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "1cce27c8212bf6c5aa96f33a3d1153887721b66c5c8cb9adeaa83cce09196b75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
